# Analysis of longitudinal data

## Part 1

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=FALSE}
library(tidyr)
library(dplyr)
library(ggplot2)
RATS <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/rats.txt", 
                   sep  ="", header = T)
RATS$ID <- factor(RATS$ID)
RATS$Group <- factor(RATS$Group)

RATSL <- read.csv("/Users/Maria/R/IODS-project/data/RATSL.csv")
RATSL$ID <- factor(RATSL$ID)
RATSL$Group <- factor(RATSL$Group)

str(RATSL) #5*176
```

### Data description

RATSL is dataset from a nutrition study conducted in three groups of rats. 
The groups were put on different diets, and each animalâ€™s body weight (grams) was recorded repeatedly over a 9-week period.


We plot the RATS values for all 16 rats
```{r}
p1 <- ggplot(RATSL, aes(x = Time, y = Weight, color = ID))
p2 <- p1 + geom_line() + scale_linetype_manual(values = rep(1:10, times=4))
p3 <- p2 + facet_grid(. ~ Group, labeller = label_both)
p4 <- p3 + theme_bw() + theme(legend.position = "none")
p5 <- p4 + theme(panel.grid.minor.y = element_blank())
p6 <- p5 + scale_y_continuous(limits = c(min(RATSL$Weight), max(RATSL$Weight)))
p6
```

We can see that:

- the weight of almost all the rats is increasing over the research period
- the animals that have higher weight values at the beginning tend to have higher values throughout the study - there are also substantial differences between rats

Then we scale the data by subtracting the mean from the original observation and then dividing by the corresponding standard deviation. 
```{r}
# Standardise the scores:
RATSL <- RATSL %>%
  group_by(Time) %>%
  mutate(stdrats = (Weight - mean(Weight))/sd(Weight) ) %>%
  ungroup()
glimpse(RATSL)
```


Then we can plot the scaled data again 
```{r}
p1 <- ggplot(RATSL, aes(x = Time, y = stdrats, color = ID))
p2 <- p1 + geom_line() + scale_linetype_manual(values = rep(1:10, times=4))
p3 <- p2 + facet_grid(. ~ Group, labeller = label_both)
p4 <- p3 + theme_bw() + theme(legend.position = "none")
p5 <- p4 + theme(panel.grid.minor.y = element_blank())
p6 <- p5 + scale_y_continuous(name = "standardized rats")
p6
```

We see that three groups differs significantly in weight.
 
```{r}
# count number of times with time 1
n <- RATSL$Time %>% unique() %>% length()
```

Now we can analyze the summary of our data 
```{r}
# Make a summary data:
RATSS <- RATSL %>%
  group_by(Group, Time) %>%
  summarise(mean=mean(Weight), se=sd(Weight)/sqrt(n) ) %>%
  ungroup()
glimpse(RATSS)
```

And we build the plot for our analysis
```{r}
p1 <- ggplot(RATSS, aes(x = Time, y = mean, color = Group, shape = Group))
p2 <- p1 + geom_line() + scale_linetype_manual(values = c(1,2,3))
p3 <- p2 + geom_point(size=3) + scale_shape_manual(values = c(1,2,3))
p4 <- p3 + geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=0.3)
p5 <- p4 + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p6 <- p5 + scale_y_continuous(name = "mean(rats) +/- se(rats)")
p6
```

The plot shows the mean profile for each study group. 
There is no overlap in the mean profiles of the three groups, so there is a significant difference between them regarding to the mean weight values.

We can also visualize data in boxplot form
```{r}
p1 <- ggplot(RATSL, aes(x = factor(Time), y = Weight, fill = Group))
p2 <- p1 + geom_boxplot(position = position_dodge(width = 0.9))
p3 <- p2 + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p4 <- p3 + scale_x_discrete(name = "time")
p4
```

The plot shows  the general increase in weight values over weeks 1-9 of the study in all the groups.

### Summary measure approach

For the summary measure approach  mean of weeks 1-9 has been chosen

Let's present the measure
```{r}
RATS11S <- RATSL %>%
  filter(Time > 1) %>%
  group_by(Group, ID) %>%
  summarise(mean=mean(Weight) ) %>%
  ungroup()
glimpse(RATS11S)
```

Now we create the boxplots for the means
```{r}
p1 <- ggplot(RATS11S, aes(x = Group, y = mean))
p2 <- p1 + geom_boxplot()
p3 <- p2 + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p4 <- p3 + stat_summary(fun.y = "mean", geom = "point", shape=23, size=4, fill = "thistle")
p5 <- p4 + scale_y_continuous(name = "mean(rats), times 2-64")
p5
```

We can see that there are outliers in each group and the second group is highly skewed. That's why, we will filter the data, where mean is larger than 580. 

```{r}
RATS11S1 <- RATS11S %>%
  filter(mean < 580)
glimpse(RATS11S1)
```

And we plot the data after filtering
```{r}
p1 <- ggplot(RATS11S1, aes(x = Group, y = mean))
p2 <- p1 + geom_boxplot()
p3 <- p2 + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p4 <- p3 + stat_summary(fun.y = "mean", geom = "point", shape=23, size=4, fill = "thistle")
p5 <- p4 + scale_y_continuous(name = "mean(rats), times 2-64")
p5
```

For further analysis of difference among the groups we can also use ANOVA test (works better here than t-test)

```{r}
# use ANOVA test
summary(aov(mean ~ Group, data = RATS11S1))
```


Due to P-value we can assume that there are significant differences among the groups but still it isn't clear which exactly.


In addition, we can check if there is any correlation between baseline measurement of the outcome variable and chosen summary measure. We will use the RATS value corresponding to the first week period as the baseline covariate. 
```{r}
# add the baseline from the original data as a new variable to the summary data
baseline <- RATS$WD1
RATS11S2 <- RATS11S %>%
  mutate(baseline)
```

```{r}
# fit the ANOVA test
fit <- lm(mean ~ baseline + Group, data = RATS11S2)
anova(fit)
```


We see that the baseline RATS is in strong relations with the mean measure.


## Part 2

```{r, include=FALSE}
# read data
BPRS <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/BPRS.txt", 
                   sep  =" ", header = T)
BPRS$subject <- seq(1, 40) # change the subject numbers to exclude mistakes
BPRS$treatment <- factor(BPRS$treatment)
BPRS$subject <- factor(BPRS$subject)
BPRSL <-  BPRS %>% gather(key = weeks, value = bprs, -treatment, -subject)
BPRSL$treatment <- factor(BPRSL$treatment)
BPRSL$subject <- factor(BPRSL$subject)
BPRSL <-  BPRSL %>% mutate(week = as.integer(substr(weeks,5, 5)))

str(BPRSL) #5*360
```

### Data description

The BPRS data includes 40 male subjects that were randomly assigned to one of two treatment groups and each subject was rated on the brief psychiatric rating scale (BPRS) measured for the period from week 0 to week 8. The BPRS assesses the level of 18 symptom constructs such as hostility, suspiciousness, hallucinations and grandiosity; each of these is rated from 1 (not present) to 7 (extremely severe). 
The scale is used to evaluate patients suspected of having schizophrenia.


First of all, let's plot the data for two treatment groups
```{r}
# plot the data with line plot
p1 <- ggplot(BPRSL, aes(x = week, y = bprs, group = subject))
p2 <- p1 + geom_line(aes(color = treatment))
p3 <- p2 + scale_x_continuous(name = "Week", breaks = seq(0, 8, 2))
p4 <- p3 + scale_y_continuous(name = "BPRS")
p5 <- p4 + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p5
```

From the plot we can see the following:

- the BPRS scores for the main part of respondents is decreasing from week 0 to week 8
-  the second treatment group has higher variance in observations


### Linear Mixed Effects Models

Now let's perform multivariate linear regression analysis to our dataset
```{r}
BPRS_reg <- lm(bprs~week+treatment, data=BPRSL)
summary(BPRS_reg)
```

We can  see that only variable "week" is significant.

#### Random intercept model

We can also fit the random intercept model
```{r}
library("lme4")
BPRS_ref <- lmer(bprs ~ week + treatment + (1 | subject), data = BPRSL, REML = FALSE)
summary(BPRS_ref)
```

We can see that standard error for variable "week" decreased in comparison to the previous multivariate linear regression model. For the variable "treatment" we see the same - it's not significant, also the standard error is even higher than  in multivariate linear regression model.
There is no change fpr variable "week" in the estimated coefficient, but the variable "treatment" changed significantly 

#### Random slope model


We  also fit the random slope model
```{r}
BPRS_ref1 <- lmer(bprs ~ week + treatment + (week | subject), data = BPRSL, REML = FALSE)
summary(BPRS_ref1)
```

We see that  this model goes better for our dataset as the likelihood ratio for the random intercept model versus the random intercept and slope model is smaller. 


```{r}
# perform an ANOVA test on the two models
anova(BPRS_ref1, BPRS_ref)
```


Then we also can fit a random intercept and slope model that allows for a week * treatment interaction
```{r}
BPRS_ref2 <- lmer(bprs ~ week * treatment + (week | subject), data = BPRSL, REML = FALSE)
summary(BPRS_ref2)
```

Here we can see that "treatment" and week * treatment interaction are not significant.
But due to likelihood ratio this model is the best of all the three of them presented.


```{r}
anova(BPRS_ref1, BPRS_ref2)
```

Here we see that p-value is high that confrms the previous result -  random intercept and slope models are not the best for this dataset.


Now we present fitted values 
```{r}
# create a vector of the fitted values
Fitted <- fitted(BPRS_ref2)
BPRSL <- BPRSL %>% mutate(Fitted)
```

Now we plot the results
```{r}
p1 <- ggplot(BPRSL, aes(x = week, y = bprs, group = subject))
p2 <- p1 + geom_line(aes(color = treatment))
p3 <- p2 + scale_x_continuous(name = "Week", breaks = seq(0, 8, 2))
p4 <- p3 + scale_y_continuous(name = "BPRS")
p5 <- p4 + theme_bw() + theme(legend.position = "right") # "none" in the book
p6 <- p5 + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p7 <- p6 + ggtitle("Observed")
graph1 <- p7
```

```{r}
p1 <- ggplot(BPRSL, aes(x = week, y = Fitted, group = subject))
p2 <- p1 + geom_line(aes(color = treatment))
p3 <- p2 + scale_x_continuous(name = "Week", breaks = seq(0, 8, 2))
p4 <- p3 + scale_y_continuous(name = "BPRS")
p5 <- p4 + theme_bw() + theme(legend.position = "right")
p6 <- p5 + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p7 <- p6 + ggtitle("Fitted")
graph2 <- p7

graph1; graph2
```
We can see the great difference between fitted and observed lines, so the interaction model doesn't work well for this dataset.
